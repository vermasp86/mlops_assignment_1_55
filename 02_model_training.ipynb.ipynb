{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cd9c101c-342a-4945-a23a-d08b98672943",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data Cleaned and Loaded.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report ,roc_auc_score,f1_score\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "import joblib # Model saving ke liye\n",
    "\n",
    "# --- 1. Data Cleaning Steps (Task 1.1) ---\n",
    "column_names = [\n",
    "    'age', 'sex', 'cp', 'trestbps', 'chol', 'fbs', 'restecg', 'thalach', \n",
    "    'exang', 'oldpeak', 'slope', 'ca', 'thal', 'target'\n",
    "]\n",
    "data_path = 'Data/processed.cleveland.data' \n",
    "df = pd.read_csv(data_path, names=column_names, na_values='?', header=None)\n",
    "\n",
    "# Handle Missing Values (Impute with Mode)\n",
    "for col in ['ca', 'thal']:\n",
    "    df[col] = df[col].fillna(df[col].mode()[0])\n",
    "\n",
    "# Binary Target Transformation\n",
    "df['target'] = df['target'].apply(lambda x: 1 if x > 0 else 0)\n",
    "\n",
    "print(\"Data Cleaned and Loaded.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "aea3c672-d539-4366-9961-11a6f916d3b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set size: 242, Testing set size: 61\n"
     ]
    }
   ],
   "source": [
    "X = df.drop('target', axis=1)\n",
    "y = df['target']\n",
    "\n",
    "# Data ko 80% Training aur 20% Testing mein split karo\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "print(f\"Training set size: {X_train.shape[0]}, Testing set size: {X_test.shape[0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "62b3f296-7e89-44dd-9a99-72f6c058fdc2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preprocessing Pipeline (ColumnTransformer) created.\n"
     ]
    }
   ],
   "source": [
    "# Features ki categories:\n",
    "numerical_features = ['age', 'trestbps', 'chol', 'thalach', 'oldpeak']\n",
    "categorical_nominal_features = ['cp', 'restecg', 'slope', 'ca', 'thal'] \n",
    "# Binary/Ordinal features (sex, fbs, exang) ko hum 'remainder' mein chhod denge.\n",
    "\n",
    "# Preprocessor: ColumnTransformer (StandardScaler + OneHotEncoder)\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', StandardScaler(), numerical_features), # Numerical data ko scale karega\n",
    "        ('cat', OneHotEncoder(handle_unknown='ignore', sparse_output=False), categorical_nominal_features) # Categorical data ko one-hot encode karega\n",
    "    ],\n",
    "    remainder='passthrough' # Baaki features (sex, fbs, exang) ko as is rakhega\n",
    ")\n",
    "\n",
    "print(\"Preprocessing Pipeline (ColumnTransformer) created.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a91d9a13-319a-489c-9e87-4b1ee6583947",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Logistic Regression...\n",
      "\n",
      "--- Logistic Regression Results ---\n",
      "Accuracy: 0.8852\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.85      0.89        33\n",
      "           1       0.84      0.93      0.88        28\n",
      "\n",
      "    accuracy                           0.89        61\n",
      "   macro avg       0.89      0.89      0.89        61\n",
      "weighted avg       0.89      0.89      0.89        61\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Logistic Regression Pipeline\n",
    "lr_pipeline = Pipeline(steps=[\n",
    "    ('preprocessor', preprocessor), # Pehle preprocessor chalao\n",
    "    ('classifier', LogisticRegression(random_state=42, solver='liblinear')) # Phir model train karo\n",
    "])\n",
    "\n",
    "print(\"Training Logistic Regression...\")\n",
    "lr_pipeline.fit(X_train, y_train)\n",
    "\n",
    "# Evaluation\n",
    "lr_pred = lr_pipeline.predict(X_test)\n",
    "lr_accuracy = accuracy_score(y_test, lr_pred)\n",
    "\n",
    "print(f\"\\n--- Logistic Regression Results ---\")\n",
    "print(f\"Accuracy: {lr_accuracy:.4f}\")\n",
    "print(classification_report(y_test, lr_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d078c239-7670-435c-b655-6c30323534ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Random Forest...\n",
      "\n",
      "--- Random Forest Results ---\n",
      "Accuracy: 0.9180\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.88      0.92        33\n",
      "           1       0.87      0.96      0.92        28\n",
      "\n",
      "    accuracy                           0.92        61\n",
      "   macro avg       0.92      0.92      0.92        61\n",
      "weighted avg       0.92      0.92      0.92        61\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Random Forest Pipeline\n",
    "rf_pipeline = Pipeline(steps=[\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('classifier', RandomForestClassifier(random_state=42, n_estimators=100))\n",
    "])\n",
    "\n",
    "print(\"Training Random Forest...\")\n",
    "rf_pipeline.fit(X_train, y_train)\n",
    "\n",
    "# Evaluation\n",
    "rf_pred = rf_pipeline.predict(X_test)\n",
    "rf_accuracy = accuracy_score(y_test, rf_pred)\n",
    "\n",
    "print(f\"\\n--- Random Forest Results ---\")\n",
    "print(f\"Accuracy: {rf_accuracy:.4f}\")\n",
    "print(classification_report(y_test, rf_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bacefb2f-4bee-4075-ab7e-fadc8058a0c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Best Model Pipeline saved to: models/random_forest_pipeline.pkl\n"
     ]
    }
   ],
   "source": [
    "# Best model ko final_pipeline variable mein store karo\n",
    "final_pipeline = rf_pipeline \n",
    "best_model_name = \"random_forest\"\n",
    "\n",
    "# --- Deliverable Requirement: Save Model Artifact ---\n",
    "# Project root mein 'models' folder banao\n",
    "if not os.path.exists('./models'):\n",
    "    os.makedirs('./models')\n",
    "\n",
    "model_filename = f'models/{best_model_name}_pipeline.pkl'\n",
    "joblib.dump(final_pipeline, model_filename)\n",
    "\n",
    "print(f\"\\nBest Model Pipeline saved to: {model_filename}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "412aacc8-5f4b-4d67-9b9f-38897fe422e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tracking to experiment: Heart_Disease_Prediction_Assignment\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\MLOpsProject\\.venv\\Lib\\site-packages\\mlflow\\tracking\\_tracking_service\\utils.py:178: FutureWarning: The filesystem tracking backend (e.g., './mlruns') will be deprecated in February 2026. Consider transitioning to a database backend (e.g., 'sqlite:///mlflow.db') to take advantage of the latest MLflow features. See https://github.com/mlflow/mlflow/issues/18534 for more details and migration guidance. For migrating existing data, https://github.com/mlflow/mlflow-export-import can be used.\n",
      "  return FileStore(store_uri, store_uri)\n"
     ]
    }
   ],
   "source": [
    "# Task 3 Started\n",
    "\n",
    "\n",
    "import mlflow\n",
    "\n",
    "# Tracking URI dobara set kar dete hain (Safety ke liye)\n",
    "mlflow.set_tracking_uri(\"./mlruns\") \n",
    "\n",
    "# Experiment ka naam\n",
    "experiment_name = \"Heart_Disease_Prediction_Assignment\"\n",
    "\n",
    "# Check aur Create Logic\n",
    "experiment = mlflow.get_experiment_by_name(experiment_name)\n",
    "\n",
    "if experiment is None:\n",
    "    # Agar experiment nahi mila, toh naya bana do\n",
    "    mlflow.create_experiment(experiment_name)\n",
    "    print(f\"Created new experiment: {experiment_name}\")\n",
    "\n",
    "# Ab Experiment set karo\n",
    "mlflow.set_experiment(experiment_name)\n",
    "\n",
    "print(f\"Tracking to experiment: {experiment_name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9e791233-864a-4b69-bd8d-fc267198b0b2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def train_and_log_model(pipeline, X_train, y_train, X_test, y_test, model_name):\n",
    "    \n",
    "    # MLflow run shuru karo\n",
    "    with mlflow.start_run(run_name=model_name) as run:\n",
    "        \n",
    "        # 1. Model Train Karo (Pipeline already created in Task 2)\n",
    "        pipeline.fit(X_train, y_train)\n",
    "        y_pred = pipeline.predict(X_test)\n",
    "        y_proba = pipeline.predict_proba(X_test)[:, 1] \n",
    "        \n",
    "        # 2. Metrics Calculate Karo\n",
    "        accuracy = accuracy_score(y_test, y_pred)\n",
    "        auc = roc_auc_score(y_test, y_proba)\n",
    "        f1 = f1_score(y_test, y_pred)\n",
    "        \n",
    "        # 3. Parameters Log Karo (Reproducibility ke liye)\n",
    "        mlflow.log_param(\"test_size\", 0.2)\n",
    "        mlflow.log_param(\"model_name\", model_name)\n",
    "        \n",
    "        if model_name == \"LogisticRegression\":\n",
    "            params = pipeline.steps[-1][1].get_params()\n",
    "            mlflow.log_params({k: v for k, v in params.items() if k in ['solver', 'C']})\n",
    "        elif model_name == \"RandomForest\":\n",
    "            mlflow.log_param(\"n_estimators\", pipeline.steps[-1][1].get_params()['n_estimators'])\n",
    "        \n",
    "        # 4. Metrics Log Karo (Reporting ke liye)\n",
    "        mlflow.log_metric(\"accuracy\", accuracy)\n",
    "        mlflow.log_metric(\"f1_score\", f1)\n",
    "        mlflow.log_metric(\"roc_auc\", auc)\n",
    "\n",
    "        # 5. Model Artifact Save Karo (Dockerization ke liye)\n",
    "        mlflow.sklearn.log_model(\n",
    "            sk_model=pipeline, \n",
    "            # artifact_path=\"model_artifact\", # Line hata di\n",
    "            registered_model_name=f\"{model_name}_Heart_Classifier\" \n",
    "        )\n",
    "        \n",
    "        print(f\"--- {model_name} Logged to MLflow. ROC AUC: {auc:.4f} ---\")\n",
    "        return auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ff591b0f-f117-4128-a84e-fe86f253f882",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\MLOpsProject\\.venv\\Lib\\site-packages\\mlflow\\tracking\\_model_registry\\utils.py:216: FutureWarning: The filesystem model registry backend (e.g., './mlruns') will be deprecated in February 2026. Consider transitioning to a database backend (e.g., 'sqlite:///mlflow.db') to take advantage of the latest MLflow features. See https://github.com/mlflow/mlflow/issues/18534 for more details and migration guidance. For migrating existing data, https://github.com/mlflow/mlflow-export-import can be used.\n",
      "  return FileStore(store_uri)\n",
      "Registered model 'LogisticRegression_Heart_Classifier' already exists. Creating a new version of this model...\n",
      "Created version '2' of model 'LogisticRegression_Heart_Classifier'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- LogisticRegression Logged to MLflow. ROC AUC: 0.9686 ---\n",
      "--- RandomForest Logged to MLflow. ROC AUC: 0.9475 ---\n",
      "\n",
      "Final Decision: logistic_regression is the best model (ROC AUC: 0.9686).\n",
      "Check MLflow UI for detailed comparison.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Registered model 'RandomForest_Heart_Classifier' already exists. Creating a new version of this model...\n",
      "Created version '2' of model 'RandomForest_Heart_Classifier'.\n"
     ]
    }
   ],
   "source": [
    "# Cell 9: Models Run Karo\n",
    "\n",
    "# Model 1 Run\n",
    "lr_auc = train_and_log_model(lr_pipeline, X_train, y_train, X_test, y_test, \"LogisticRegression\") \n",
    "\n",
    "# Model 2 Run\n",
    "rf_auc = train_and_log_model(rf_pipeline, X_train, y_train, X_test, y_test, \"RandomForest\") \n",
    "\n",
    "# Best Model Select Karo\n",
    "best_model_pipeline = rf_pipeline if rf_auc > lr_auc else lr_pipeline\n",
    "best_model_name = \"random_forest\" if rf_auc > lr_auc else \"logistic_regression\"\n",
    "\n",
    "print(f\"\\nFinal Decision: {best_model_name} is the best model (ROC AUC: {max(lr_auc, rf_auc):.4f}).\")\n",
    "print(\"Check MLflow UI for detailed comparison.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83926d2c-1bcd-4c95-9e9d-a7db4866ca54",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "816c4b2e-0829-4bc6-9ade-f72cb57b5823",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
